import csv
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from pathlib import Path
import shap
import uuid
import zipfile
from catboost import CatBoostClassifier
from shutil import copytree


def waterfall(output_dir, model, sample_ids, X, display_features=10):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X)
    num_features = len(shap_values)
    prediction = model.predict(X)
    for i, sample in enumerate(sample_ids):
        pred_cls_idx = np.where(model.classes_ == prediction[i][0])[0][0]
        shap.waterfall_plot(shap.Explanation(values=shap_values[pred_cls_idx][i],
                                             base_values=explainer.expected_value[pred_cls_idx], data=X.iloc[i],
                                             feature_names=X.columns.tolist()),
                            max_display=min(display_features, num_features),
                            show=False)
        fig = plt.gcf()
        plt.title("{}_feature_importance.png".format(sample))
        fig.savefig(os.path.join(output_dir, sample, "{}_feature_importance.png".format(sample)), bbox_inches='tight')
        plt.close()


def load_model():
    model = CatBoostClassifier(
            loss_function='MultiClass',
            custom_metric='Accuracy',
            learning_rate=0.15,
            random_seed=42,
            l2_leaf_reg=3,
            iterations=3)
    model_path = os.path.join('/kb/module/data', 'model_app.json')
    model.load_model(model_path, format='json')
    return model


def load_inference_data():
    # inference data set's first column is data sample id
    inference_data_path = os.path.join('/kb/module/data', 'enigma.tsv')
    with open(inference_data_path, 'r') as f:
        df = pd.read_csv(f, sep="\t")
    X = df.iloc[:, 1:]
    sample_id = df[df.columns[0]]
    return sample_id, X


def inference(model, sample_ids, inference_data, n_labels=10):
    prediction_label = model.predict(inference_data)
    prediction_prob = model.predict(inference_data, prediction_type="Probability")
    res = []
    class_list = model.classes_
    output_dir = '/opt/work/outputdir'
    for i, sample in enumerate(sample_ids):
        # 1. set path for tsv table and plot
        sample_dir = os.path.join(output_dir, sample)
        figure_path = os.path.join(sample_dir, "{}_top_predicted_biomes.png".format(sample))
        tsv_path = os.path.join(sample_dir, "{}_top_predicted_biomes.tsv".format(sample))
        Path(sample_dir).mkdir(parents=True, exist_ok=True)

        # 2. extract top predicted biomes
        sample_prob = prediction_prob[i]
        sorted_idx = np.argsort(sample_prob)[::-1]  # from highest to lowest
        biome_prob_pair = [(class_list[idx], sample_prob[idx]) for idx in sorted_idx[:n_labels]]

        # 3. save top predicted biome bar plot
        biome, prob = zip(*biome_prob_pair)
        plt.barh(biome, prob)
        plt.title('{}'.format(sample))
        plt.gca().invert_yaxis()
        plt.xlabel('probability')
        plt.savefig(figure_path, bbox_inches='tight')
        plt.close()

        # 4. save top predicted biome tsv table
        with open(tsv_path, 'w') as f:
            writer = csv.writer(f, delimiter="\t")
            writer.writerow(['Predicted Biome', 'Probabality'])
            for biome, prob in biome_prob_pair:
                writer.writerow([biome, prob])
    return output_dir


def generate_output_file_list(result_directory, shared_folder):
    output_files = list()
    output_directory = os.path.join(shared_folder, str(uuid.uuid4()))
    os.mkdir(output_directory)
    result_file = os.path.join(output_directory, 'biome_classification_result.zip')

    with zipfile.ZipFile(result_file, 'w',
                         zipfile.ZIP_DEFLATED,
                         allowZip64=True) as zip_file:
        for root, dirs, files in os.walk(result_directory):
            for file in files:
                if file.endswith('tsv') or file.endswith('png'):
                    zip_file.write(os.path.join(root, file),
                                   os.path.join(os.path.basename(root), file))

    output_files.append({'path': result_file,
                         'name': os.path.basename(result_file),
                         'label': os.path.basename(result_file),
                         'description': 'File(s) generated by DESeq2 App'})
    return output_files


def tsv2html(tsv_file_name, html_file_name):
    df = pd.read_csv(tsv_file_name, sep='\t', header=0)
    old_width = pd.get_option('display.max_colwidth')
    pd.set_option('display.max_colwidth', -1)
    with open(html_file_name, 'w') as html_file:
        html_file.write(df.to_html(index=False))
    pd.set_option('display.max_colwidth', old_width)


def generate_html_list(shared_folder):
    output_report_directory = os.path.join(shared_folder, "output_report_directory")
    tsv_file_path = '/opt/work/outputdir/prediction.tsv'
    html_file_path = '/opt/work/outputdir/prediction.html'
    tsv2html(tsv_file_path, html_file_path)

    copytree("/opt/work/outputdir", output_report_directory)
    html_links = [
        {
            "path": output_report_directory,
            "name": 'prediction.html',
            "description": 'Biome prediction report',
        }
    ]
    return html_links




